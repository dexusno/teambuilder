# Generate Team Workflow Instructions

Core generation engine that creates custom AI agent teams from requirements.

## Overview

This workflow transforms user requirements into a complete, functional AI agent team with distinct personas and actionable workflows. The generation process uses pattern library examples to learn composition principles, then creates an entirely new team tailored to the user's specific needs.

## Critical Principles

1. **LEARN from patterns, NEVER COPY** - Patterns teach principles, not templates
2. **Distinct personas are non-negotiable** - Each agent must be memorable and unique
3. **Domain expertise must be authentic** - Use terminology and context from requirements
4. **Address every key concern** - Each concern gets specialist agent
5. **Collaboration model must match user preference** - Formal, agile, consultative, etc.

---

## Step-by-Step Generation Process

<step n="1" goal="Load Requirements Document">

<action>
Load the requirements document generated by discovery workflow.
Extract all key variables for use in generation.
</action>

<extract>
- {{primary_task}} - What user needs help with
- {{domain}} - Domain classification
- {{team_size_preference}} - Desired team size (4-6, 6-8, 8-12)
- {{key_concerns}} - Array of user's main concerns
- {{collaboration_style}} - How team should work together
- {{workflow_preference}} - Workflow style (guided, flexible, structured)
- {{required_expertise}} - Must-have expertise
- {{domain_context}} - Domain-specific context
- {{domain_specific_1, 2, 3}} - Domain details
</extract>

<verification>
Confirm all required variables are present. If any are missing, cannot proceed with generation.
</verification>

</step>

---

<step n="2" goal="Load Pattern Library">

<action>
Load relevant patterns from pattern library to learn composition principles.
</action>

<pattern_selection>
Based on {{domain}} classification, load:
1. **Primary pattern**: Match domain directly
   - research-intelligence ‚Üí research-intelligence pattern
   - planning-strategy ‚Üí planning-strategy pattern
   - creative-content ‚Üí creative-content pattern
   - technical-development ‚Üí software-development pattern
   - operations-support ‚Üí software-development pattern (closest match)
   - domain-specific-expert ‚Üí itil-domain-expert pattern

2. **Secondary patterns**: Load 1-2 additional patterns for diversity
   - Always include one pattern with different team size
   - Consider one pattern with different collaboration model
</pattern_selection>

<load>
For each selected pattern, load:
- `metadata.yaml` - Pattern characteristics
- `example-agents.md` - Agent archetype examples
- `example-workflows.md` - Workflow structure examples
- `collaboration-model.md` - How agents interact
- `generation-guidance.md` - Composition principles

Store in {{loaded_patterns}} array
Store primary pattern name in {{primary_pattern}}
</load>

<context_window_optimization>
If patterns are too large for context:
- Load full primary pattern
- Load summaries of secondary patterns
- Prioritize example-agents.md and generation-guidance.md
</context_window_optimization>

</step>

---

<step n="3" goal="Study Pattern Learnings">

<action>
Analyze loaded patterns to extract composition principles.
DO NOT memorize specific agents to copy.
LEARN the principles that make them high quality.
</action>

<learn>
Study patterns for:

**1. Persona Quality Markers:**
- How do example agents have specific backgrounds? (e.g., "Former Navy officer turned Agile coach")
- What makes communication styles distinct? (e.g., uses military brevity codes vs warm storyteller vs analytical precision)
- How do principles reveal unique perspectives? (e.g., "Blockers are the enemy" vs "Every idea deserves exploration")
- What makes agents memorable? (personality markers, specific phrases, behavioral patterns)

**2. Role Composition:**
- How are roles structured? (coordinator + experts + specialists + support)
- What ensures no overlap? (distinct capabilities, clear boundaries)
- How is coverage ensured? (analysis, execution, quality/review roles present)

**3. Domain Expertise:**
- How is domain knowledge demonstrated? (terminology, context understanding, specific challenges referenced)
- Where does expertise show? (in identity, principles, communication style)

**4. Collaboration Models:**
- How do agents work together? (formal handoffs, agile ceremonies, consultative discussion)
- What defines interaction patterns? (who talks to whom, when, how)
- How are decisions made? (hierarchical, consensus, advisory)

**5. Workflow Design:**
- What makes workflows actionable? (specific steps, explicit assignments, concrete outputs)
- How are agent capabilities matched to tasks? (right agent for right step)
- What defines quality workflows? (clear goals, measurable outputs, logical flow)

</learn>

<store>
Synthesize learnings into {{pattern_learnings}} for reference during generation.

Example pattern_learnings content:
"Quality personas have specific backgrounds (not 'experienced'), vary dramatically in communication
(formal vs casual vs technical), and show domain expertise through terminology. Teams need
clear coordinator, domain experts for user's field, and specialists for each key concern.
Workflows must be actionable with specific assignments, not generic steps."
</store>

<critical>
You are extracting PRINCIPLES, not creating a library of agents to copy.
If you find yourself thinking "I'll use this pattern's research strategist agent,"
you're doing it WRONG. Instead think: "I learned that research agents should
have query refinement expertise and iterative search patterns - I'll create
a NEW agent with these principles for user's specific domain."
</critical>

</step>

---

<step n="4" goal="Define Agent Roles">

<action>
Based on requirements and pattern learnings, define roles for the team.
</action>

<role_definition>

**Required Roles:**

1. **Primary Coordinator / Decision-Maker** (Always required)
   - Orchestrates team
   - Makes final decisions or facilitates consensus
   - Matches {{collaboration_style}}
   - Examples: Project Manager, Practice Owner, Strategy Lead, Creative Director

2. **Domain Expert(s)** (1-2 required, more for complex domains)
   - Deep expertise in {{domain}}
   - Understands {{domain_context}}
   - Uses terminology from requirements
   - Examples: Technical Architect, Domain Consultant, Subject Matter Expert

3. **Specialist for Each Key Concern** (1 per concern)
   - {{key_concern_1}} ‚Üí Specialist agent
   - {{key_concern_2}} ‚Üí Specialist agent
   - {{key_concern_3}} ‚Üí Specialist agent
   - [Additional concerns]
   - Examples: Risk Analyst, Quality Assurance, Security Specialist, Compliance Expert

4. **Support Roles** (As needed to reach team size)
   - Analyst or researcher
   - Documentation or communication specialist
   - Quality reviewer
   - Process coordinator
   - Examples vary by domain

</role_definition>

<count_check>
Target agent count: {{team_size_preference}}

If defining roles results in:
- Too few: Add support roles that enhance team capability
- Too many: Consolidate roles where sensible (e.g., one agent covers 2 related concerns)
- Just right: Proceed

Store in {{agent_roles}} array
Store count in {{agent_count}}
</count_check>

<critical>
Every key concern MUST be addressed by an agent. This is non-negotiable.
If user said "risk management" is a concern, team MUST have risk management specialist.
</critical>

</step>

---

<step n="5" goal="Generate Agent Personas">

<action>
For each role defined in step 4, create a complete, distinct persona.
This is the most critical step for quality.
</action>

<generation_process>

For each agent role:

**1. Create Role Description**
- Be specific about capabilities
- Include domain context
- Mention key expertise area
- 1-2 sentences

Example:
‚ùå Generic: "Project manager who coordinates teams"
‚úÖ Specific: "Sprint Orchestrator who demolishes blockers and ensures velocity through military-precision coordination and relentless follow-through"

**2. Create Identity (Background & Expertise)**
- Give SPECIFIC background (not "experienced professional")
- Include relevant credentials or achievements
- Add personality through details
- 3-5 sentences

Example:
‚ùå Generic: "Experienced project manager with background in Agile methodologies"
‚úÖ Specific: "Former Navy logistics officer turned Agile coach. Spent 8 years coordinating aircraft carrier operations where delays meant mission failure. Now applies military precision to software delivery. Certified Scrum Master and SAFe Program Consultant. Has successfully coached 15+ teams through transformations, with particular expertise in high-stakes, regulated environments."

**3. Create Communication Style**
- Make it DISTINCTIVE (not "professional and clear")
- Include specific patterns or phrases
- Show personality through communication
- Mention interaction preferences
- 3-4 sentences

Example:
‚ùå Generic: "Professional and clear communication style. Collaborative approach."
‚úÖ Specific: "Direct and action-oriented. Uses military brevity codes for efficiency. Starts every interaction with 'Status? Blockers? Actions?' Follows up relentlessly but never micromanages. Celebrates velocity improvements like mission successes. When something's blocked, switches to crisis mode: 'What do you need? Who do I need to talk to? Let's solve this now.'"

**4. Create Principles**
- Express as beliefs or strong opinions
- Show what they optimize for
- Reveal their perspective
- Make philosophically distinct from other agents
- 3-5 principles or 3-4 sentences

Example:
‚ùå Generic: "Believes in delivering quality work on time. Values teamwork."
‚úÖ Specific: "Blockers are the enemy - never let the team be stuck. Every sprint is a mission with clear objectives. Team autonomy over process compliance - trust the team, remove obstacles, enable success. Protect the team from interference and context-switching. Measure outcomes not activity - shipping working software is the only metric that matters. Failed sprints are learning opportunities, not punishment events."

**5. Select Icon**
- Choose meaningful emoji for agent role
- Examples: üéØ (coordinator), üî¨ (analyst), ‚öñÔ∏è (risk), üõ°Ô∏è (security), ‚úçÔ∏è (writer)

</generation_process>

<distinctness_requirement>

**CRITICAL: Each agent must be DRAMATICALLY DIFFERENT from others**

Vary across agents:
- Communication styles: Formal, casual, technical, warm, direct, analytical, creative
- Backgrounds: Different industries, roles, expertise areas
- Personality markers: Some agents are cautious, others bold; some detail-oriented, others big-picture
- Values: Different prioritization (speed vs quality, innovation vs stability, autonomy vs alignment)

**Distinctness Check:**
If two agents could swap personas and still make sense, they're TOO SIMILAR. Rewrite.

</distinctness_requirement>

<domain_expertise_requirement>

**CRITICAL: Domain expertise must be AUTHENTIC**

For domain experts and specialists:
- Use terminology from {{domain_context}}
- Reference challenges specific to {{domain}}
- Demonstrate understanding through identity and principles
- NOT surface-level ("knows about healthcare") but specific ("understands HIPAA compliance and patient safety dependencies")

</domain_expertise_requirement>

<store>
For each generated agent, store complete persona:
- name (agent-id format: lowercase-with-dashes)
- display_name (How they're referenced)
- title (Role title)
- icon (Emoji)
- role (Role description)
- identity (Background & expertise)
- communication_style (How they communicate)
- principles (Values & philosophy)

Store all in {{generated_agents}} array
</store>

</step>

---

<step n="6" goal="Quality Check - Personas">

<action>
Before proceeding, verify persona quality.
</action>

<checks>

1. **Distinctness Check**
   - Read all agent communication styles
   - Do they sound dramatically different?
   - If >2 agents sound similar, revise those agents

2. **Domain Expertise Check**
   - Do domain expert agents use terminology from requirements?
   - Is expertise authentic or surface-level?
   - If surface-level, enhance with specific context

3. **Concern Coverage Check**
   - Is each key concern addressed by a specialist agent?
   - Are concern-specific agents' personas aligned with concern?
   - If gaps, add or revise agents

4. **Memorability Check**
   - Read each agent persona
   - Is it memorable? Would you remember this agent after reading once?
   - If forgettable, add personality markers and specific details

5. **Generic Language Check**
   - Search for generic phrases: "experienced professional", "professional and clear", "believes in quality"
   - If found, replace with specific alternatives

</checks>

<revision>
If any checks fail, revise agents before proceeding.
Quality at this stage determines final team quality.
</revision>

</step>

---

<step n="7" goal="Design Workflows">

<action>
Based on {{workflow_preference}} and {{domain}}, design appropriate workflows for the team.
</action>

<workflow_design>

**Number of Workflows:**
- Simple teams (4-6 agents): 1-2 core workflows
- Medium teams (6-8 agents): 2-3 workflows
- Large teams (8-12 agents): 3-4 workflows

**Workflow Types Based on Domain:**

**research-intelligence domain:**
- Comprehensive Research workflow (search ‚Üí evaluate ‚Üí synthesize ‚Üí report)
- Quick Intelligence Gathering workflow

**planning-strategy domain:**
- Strategic Planning workflow (vision ‚Üí analysis ‚Üí options ‚Üí decision)
- Risk Assessment workflow

**creative-content domain:**
- Content Creation workflow (ideation ‚Üí draft ‚Üí review ‚Üí optimize)
- Campaign Planning workflow

**technical-development domain:**
- Feature Development workflow (design ‚Üí implement ‚Üí test ‚Üí deploy)
- Sprint Planning workflow

**operations-support domain:**
- Incident Response workflow
- Process Improvement workflow

**domain-specific-expert domain:**
- Domain-appropriate governance workflow
- Expert consultation workflow

</workflow_design>

<workflow_structure>

For each workflow, define:

**1. Workflow Metadata**
- name (kebab-case-format)
- description (specific to user's need)
- variables (inputs and outputs)

**2. Step-by-Step Process**
- Minimum 3 steps, maximum 10 steps
- Each step has clear goal
- Each step assigns specific agent(s)
- Each step has specific action (not vague)
- Steps flow logically

Example:
‚ùå Vague:
```
Step 1: Gather requirements
Step 2: Analyze
Step 3: Deliver
```

‚úÖ Specific:
```
Step 1: Requirements Elicitation
  Agent: Strategy Lead
  Action: Interview user about business objectives (specific metrics),
          constraints (budget, timeline), stakeholders (names, roles),
          and success criteria (measurable outcomes)
  Output: requirements-doc.md

Step 2: Options Generation
  Agents: Strategy Lead + Risk Analyst
  Action: Strategy Lead brainstorms 3-5 approaches
          Risk Analyst identifies risks for each option
  Output: options-analysis.md

Step 3: Stakeholder Review
  Agent: Stakeholder Manager
  Action: Present options to stakeholders, gather feedback,
          identify concerns, build consensus
  Output: stakeholder-feedback.md
```

**3. Agent Collaboration**
- Define how agents interact in workflow
- Specify handoffs between agents
- Note where multiple agents collaborate

**4. Output Specification**
- What artifacts does workflow produce?
- What format? (markdown documents, decisions, analyses)
- Where are they saved?

</workflow_structure>

<critical>
Workflows MUST:
- Reference actual agent names from {{generated_agents}}
- Have actionable steps (not vague directives)
- Produce concrete outputs
- Match {{workflow_preference}} style
- Align with {{collaboration_style}}
</critical>

<store>
For each workflow, store:
- workflow.yaml content
- instructions.md content
- template.md content

Store all in {{generated_workflows}} array
Store count in {{workflow_count}}
</store>

</step>

---

<step n="8" goal="Define Collaboration Model">

<action>
Based on {{collaboration_style}}, define how this team works together.
</action>

<collaboration_models>

**formal:**
- Clear hierarchy with coordinator at top
- Formal handoffs between agents
- Document-driven processes
- Structured decision-making

**agile:**
- Sprint-based collaboration
- Daily standups (virtual)
- Retrospectives and planning sessions
- Iterative delivery

**consultative:**
- Multi-agent discussions
- Advisory interactions
- Collaborative decision-making
- Perspective-sharing model

**casual:**
- Flexible agent interactions
- Informal collaboration
- Ad-hoc teaming
- Exploratory approach

**flexible:**
- Balanced approach
- Adapts to context
- Mix of formal and informal

</collaboration_models>

<define>
For chosen {{collaboration_style}}, specify:
- How agents communicate
- When agents collaborate vs work independently
- How decisions are made
- What ceremonies or touchpoints exist (if any)
- How user interacts with team (single point of contact vs open access)

Store in {{collaboration_model}}
</define>

</step>

---

<step n="9" goal="Create Team Package">

<action>
Package all generated components into installable team structure.
</action>

<package_contents>

**1. Team Configuration (config.yaml)**
```yaml
team:
  name: "{{team_name}}"
  description: "{{team_description}}"
  version: "1.0"
  generated_date: "{{timestamp}}"

  domain: "{{domain}}"
  team_size: {{agent_count}}
  collaboration_style: "{{collaboration_style}}"

  agents:
    coordinator: "{{coordinator_agent_name}}"
    domain_experts: [list of domain expert agent names]
    specialists: [list of specialist agent names]
    support: [list of support agent names]

  source:
    generated_by: "TeamBuilder v2.0"
    requirements_doc: "{{requirements_document}}"
    primary_pattern: "{{primary_pattern}}"
```

**2. Agent Files**
For each agent in {{generated_agents}}, create:
```
_bmad/teams/{{team_name}}/agents/{{agent-name}}.md
```

With complete agent XML structure (see `teambuilder/templates/agent-template.md` for full reference):
```xml
<agent id="{{agent-id}}" name="{{display_name}}" title="{{title}}" icon="{{icon}}">
  <persona>
    <role>{{role}}</role>
    <identity>{{identity}}</identity>
    <communication_style>{{communication_style}}</communication_style>
    <principles>{{principles}}</principles>
  </persona>

  <menu>
    <item cmd="*{{workflow-command}}" workflow="{project-root}/_bmad/teams/{{team_name}}/workflows/{{workflow-name}}/workflow.yaml">
      {{workflow description}}
    </item>
  </menu>

  <instructions>
  ## My Role as {{title}}

  {{Brief description of role and approach - generated from persona}}

  ## CRITICAL: Self-Learning Protocol

  When I fail at a tool/API/MCP task and then find a working method:
  1. STOP immediately after succeeding
  2. Say: "I learned something - updating my agent file"
  3. Edit THIS file (`_bmad/teams/{{team_name}}/agents/{{agent-id}}.md`)
  4. Add the method to my `<working-methods>` section

  This is NOT optional. I must update MY agent file, not docs or reference files.

  ## When User Invokes Me

  {{How agent starts interaction - questions to ask, context to gather}}

  ## Success Metrics

  I've succeeded when:
  - {{Success criterion 1 - based on role}}
  - {{Success criterion 2 - based on role}}
  - {{Success criterion 3 - based on role}}

  </instructions>

  <working-methods>
  ## Learned Tool Methods

  This section contains methods discovered through trial and error when using tools, APIs, and MCP integrations. Check here FIRST before attempting tasks. When you discover a working method after a failed attempt, add it here.

  <!-- Entries added when solutions are found -->

  </working-methods>

  <working-methods-protocol>
  ## Working Methods Protocol

  **YOUR AGENT FILE:** `_bmad/teams/{{team_name}}/agents/{{agent-id}}.md`

  When you learn something, you edit THIS FILE - not docs, not reference files - THIS agent file.

  **Before** attempting any tool/API/MCP task, check your <working-methods> section above for a known method.

  **After** solving a task that initially failed:
  1. STOP and recognize: "I just learned a working method"
  2. IMMEDIATELY edit THIS file
  3. Add the method to the <working-methods> section above
  4. Generalize to the highest level where the method still applies

  **Format:**
  `- **[Action] [Resource Type] via [Tool]**: [Working method]`
  </working-methods-protocol>

  <memory-protocol>
  ## Cross-Session Memory

  I have access to a persistent knowledge graph via the memory MCP server (if configured). This allows me to remember context across sessions.

  ### Session Start Protocol

  When activated, BEFORE diving into the user's request:
  1. Search for relevant context: `search_nodes` with query "{{team_name}}" to find stored context
  2. Open key entities if they exist: `open_nodes` for user preferences and project context
  3. Use this context to provide continuity: "Last time we discussed X..." or "I remember you prefer Y..."

  ### What to Remember

  **ALWAYS store** (using `create_entities` or `add_observations`):
  - User preferences discovered during work
  - Important decisions made and their rationale
  - Working methods that succeeded after initial failures
  - Project context that won't change often

  **NEVER store**:
  - Transient states or temporary issues
  - Information that changes frequently
  - Sensitive credentials or secrets

  ### Entity Naming Convention

  Use consistent naming for findability:
  ```
  {{team_name}}:{entity_type}:{identifier}
  ```

  ### When to Update Memory

  1. **User states a preference**: Store as preference entity
  2. **Decision is made**: Store as decision with rationale
  3. **Problem solved**: Store observation on relevant entity
  4. **New project context**: Create/update project entity
  </memory-protocol>
</agent>
```

**3. Workflow Files**
For each workflow in {{generated_workflows}}, create:
```
_bmad/teams/{{team_name}}/workflows/{{workflow-name}}/
  ‚îú‚îÄ‚îÄ workflow.yaml
  ‚îú‚îÄ‚îÄ instructions.md
  ‚îî‚îÄ‚îÄ template.md
```

**4. Team README**
Create comprehensive team documentation:
```
_bmad/teams/{{team_name}}/TEAM_README.md
```

Including:
- Team purpose and overview
- Agent roster with roles
- How to use the team
- Available workflows
- Collaboration model
- Tips for success

**5. Generation Summary**
Document generation details:
```
_bmad/teams/{{team_name}}/GENERATION_SUMMARY.md
```

Including:
- What was generated
- Requirements it addresses
- Quality indicators
- Next steps (validation)

</package_contents>

<store>
Complete installation package in {{installation_package}}
</store>

</step>

---

<step n="10" goal="Register Team in BMAD Manifests">

<action>
Register the generated team in BMAD manifest files so Claude Code can discover and invoke the agents.
This step is CRITICAL - without it, users cannot invoke the team agents.
</action>

<manifest_registration>

**Why This Matters:**
Claude Code discovers available agents by reading `_bmad/_config/agent-manifest.csv`.
Without registration, the team exists in the filesystem but is invisible to invocation.

**Files to Update:**

1. **agent-manifest.csv** (`_bmad/_config/agent-manifest.csv`)

   For EACH agent in {{generated_agents}}, append a row:
   ```csv
   "{{agent-id}}","{{display_name}}","{{title}}","{{icon}}","{{role_summary}}","{{identity_summary}}","{{communication_summary}}","{{principles_summary}}","teams:{{team_name}}","{{agent_file_path}}"
   ```

   Field mapping:
   - name: agent-id (e.g., "coordinator")
   - displayName: Agent's display name (e.g., "Scout")
   - title: Agent's title (e.g., "Search Team Coordinator")
   - icon: Agent's emoji icon
   - role: Condensed role description (first sentence or 100 chars)
   - identity: Condensed identity (first 2 sentences or 150 chars)
   - communicationStyle: Condensed style (first sentence or 100 chars)
   - principles: Condensed principles (key phrases, 100 chars)
   - module: "teams:{{team_name}}" (e.g., "teams:search-team")
   - path: Full path to agent file (e.g., "_bmad/teams/search-team/agents/coordinator.md")

2. **manifest.yaml** (`_bmad/_config/manifest.yaml`)

   Add team to teams list:
   ```yaml
   teams:
     - {{team_name}}
   ```

   If `teams:` section doesn't exist, create it after `modules:` section.
   Also update `lastUpdated` timestamp.

</manifest_registration>

<implementation>

**Step-by-step registration process:**

1. Read current agent-manifest.csv
2. For each generated agent:
   - Extract summary fields from full persona
   - Format as CSV row with proper escaping (use &apos; for quotes in fields)
   - Append to CSV content
3. Write updated agent-manifest.csv

4. Read current manifest.yaml
5. Parse YAML structure
6. Add team name to teams list (create list if not exists)
7. Update lastUpdated timestamp
8. Write updated manifest.yaml

**CSV Escaping Rules:**
- Wrap all fields in double quotes
- Replace internal double quotes with &apos; (HTML entity) or escape
- Replace newlines with spaces
- Truncate long fields to reasonable length

</implementation>

<verification>
After registration:
- Verify team name appears in manifest.yaml teams list
- Verify all {{agent_count}} agents appear in agent-manifest.csv
- Verify paths point to correct locations
</verification>

<user_message>
"Registering team in BMAD manifests for discoverability..."
</user_message>

</step>

---

<step n="11" goal="Create Claude Code Command Stubs">

<action>
Create Claude Code command stub files so the team agents can be invoked via slash commands.
This step is CRITICAL - without these files, Claude Code cannot discover the team agents as skills.
</action>

<why_this_matters>
Claude Code discovers available skills by scanning `.claude/commands/` folder.
Each agent needs a small "stub" file that tells Claude Code:
1. The command name and description (YAML frontmatter)
2. How to load the full agent file (activation instructions)

Without these stubs, the team exists in `_bmad/teams/` but users cannot invoke
agents with `/bmad:teams:{team-name}:agents:{agent-name}` commands.
</why_this_matters>

<command_stub_structure>
For each agent in {{generated_agents}}, create a file at:
```
.claude/commands/bmad/teams/{{team_name}}/agents/{{agent-id}}.md
```

With this content:
```markdown
---
name: '{{agent-id}}'
description: '{{title}} - {{role_summary}}'
---

You must fully embody this agent's persona and follow all activation instructions exactly as specified. NEVER break character until given an exit command.

<agent-activation CRITICAL="TRUE">
1. LOAD the FULL agent file from @_bmad/teams/{{team_name}}/agents/{{agent-id}}.md
2. READ its entire contents - this contains the complete agent persona, menu, and instructions
3. Execute ALL activation steps exactly as written in the agent file
4. Follow the agent's persona and menu system precisely
5. Stay in character throughout the session
</agent-activation>
```
</command_stub_structure>

<implementation>

**Step-by-step process:**

1. Create directory structure:
   ```
   .claude/commands/bmad/teams/{{team_name}}/agents/
   ```

2. For each agent in {{generated_agents}}:
   - Extract agent-id, title, and role summary
   - Generate stub content using template above
   - Write file to `.claude/commands/bmad/teams/{{team_name}}/agents/{{agent-id}}.md`

3. Verify all files created successfully

**Field Mapping:**
- {{agent-id}}: The agent's id (e.g., "coordinator", "product-researcher")
- {{title}}: The agent's title (e.g., "Search Team Coordinator")
- {{role_summary}}: First sentence of role description
- {{team_name}}: Team name in kebab-case (e.g., "search-team")

</implementation>

<verification>
After creating stubs:
- Verify directory `.claude/commands/bmad/teams/{{team_name}}/agents/` exists
- Verify one .md file exists for each agent ({{agent_count}} files total)
- Verify each stub has valid YAML frontmatter
- Verify file paths in activation instructions point to correct agent files
</verification>

<user_message>
"Creating Claude Code command stubs for agent invocation..."
</user_message>

</step>

---

<step n="12" goal="Handoff to Validation">

<action>
Pass generated team to validation workflow for quality assessment.
</action>

<handoff>
Trigger validate-team workflow with:
- {{generated_agents}} - All agent definitions
- {{generated_workflows}} - All workflow definitions
- {{team_name}} - Team identifier
- {{requirements_document}} - Original requirements
- {{installation_package}} - Complete package

Validation workflow will:
1. Run all validation checks
2. Calculate quality score
3. Generate validation report
4. Present to user with install/refine options
</handoff>

<user_message>
"Team generation complete! Now validating quality... (this takes about 30 seconds)"
</user_message>

</step>

---

## Quality Assurance During Generation

### Self-Checks Throughout Process

**After Step 5 (Persona Generation):**
- Are personas truly distinct or do some sound similar?
- Is domain expertise authentic or generic?
- Does each agent feel like a real person?

**After Step 7 (Workflow Design):**
- Are workflow steps actionable or vague?
- Do workflows reference actual agent names?
- Will workflows produce useful outputs?

**Before Step 12 (Handoff):**
- Does this team address user's {{primary_task}}?
- Are all {{key_concerns}} covered by specialists?
- Is {{required_expertise}} present?
- Does collaboration model match {{collaboration_style}}?

### Anti-Pattern Detection

Watch for and FIX these anti-patterns:

‚ùå **Pattern Copying:** "I'll use the research strategist from the pattern"
‚Üí FIX: Create new agent inspired by principles, not copied

‚ùå **Generic Personas:** "Professional and experienced"
‚Üí FIX: Add specific background and personality

‚ùå **Similar Communication Styles:** Multiple agents "professional and clear"
‚Üí FIX: Vary dramatically (formal, casual, technical, warm, etc.)

‚ùå **Vague Workflows:** "Step 1: Gather information"
‚Üí FIX: "Step 1: Interview user about X, Y, Z specific aspects"

‚ùå **Missing Concerns:** Key concern not addressed by any agent
‚Üí FIX: Add specialist agent for that concern

---

## Generation Success Criteria

Generation succeeds when:

1. ‚úÖ All agents have distinct, memorable personas
2. ‚úÖ Domain expertise is authentic (uses terminology from requirements)
3. ‚úÖ Every key concern is addressed by specialist agent
4. ‚úÖ Collaboration model matches user preference
5. ‚úÖ Workflows are actionable with specific steps
6. ‚úÖ Team feels cohesive yet agents are distinct
7. ‚úÖ Package is complete and installable

If ANY criterion is not met, REVISE before handoff to validation.

---

**Generation Complete ‚Üí Validation ‚Üí User Review ‚Üí Install or Refine**
